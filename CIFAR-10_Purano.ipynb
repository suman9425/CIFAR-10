{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1IJ_aaQDG88v7Si76_zPk25bC2vP8GceE","authorship_tag":"ABX9TyPAjeyZcUqxgNnsuLDWVZ+M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IIWT1YiXaigq"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optimm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["This cocde converts images into tensors and normalizes pixel values of all RGB channels to the range [-1, 1]."],"metadata":{"id":"pIzMtjkKBaSI"}},{"cell_type":"code","source":[" transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"],"metadata":{"id":"yVVsxo553K6o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code downloads the CIFAR-10 dataset, applies the transform to images, and then loads them into mini-batches using `DataLoader` for training (`batch_size=4`, shuffled) and testing (`batch_size=32`, shuffled)."],"metadata":{"id":"OC9Anftimr6K"}},{"cell_type":"code","source":["train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=4,\n","                                          shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"],"metadata":{"id":"2d3-F3ix3lFK","executionInfo":{"status":"ok","timestamp":1755393737939,"user_tz":-345,"elapsed":15380,"user":{"displayName":"Suman Kulung","userId":"01909858237713173636"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"becc0225-17cd-400a-d088-6089c3d44364"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:10<00:00, 15.7MB/s]\n"]}]},{"cell_type":"code","source":["image, label = train_data[0]"],"metadata":{"id":"vhXJUGB_4evs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5CuBCAB45k9","executionInfo":{"status":"ok","timestamp":1755266701737,"user_tz":-345,"elapsed":58,"user":{"displayName":"Suman Kulung","userId":"01909858237713173636"}},"outputId":"62870b35-5b4c-4e18-80bd-f7d36639c0ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 32, 32])"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["This code defines a CNN with three convolution–batchnorm–ReLU–pooling blocks followed by fully connected layers with dropout, outputting class scores for 10 CIFAR-10 categories."],"metadata":{"id":"TZSQdOz0BvP2"}},{"cell_type":"code","source":["class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"8oDBO0vp4-um"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code builds a CNN that extracts features through three conv-batchnorm-ReLU-pool layers, flattens them, and classifies into 10 classes using fully connected layers with dropout."],"metadata":{"id":"X_Gt83bf_4v2"}},{"cell_type":"code","source":["class NeuralNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Convolution layers\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","\n","        # Pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(128 * 4 * 4, 256)  # 32x32 -> 4x4 after pooling 3 times\n","        self.dropout1 = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc3 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        x = torch.flatten(x, 1)\n","        x = self.dropout1(F.relu(self.fc1(x)))\n","        x = self.dropout2(F.relu(self.fc2(x)))\n","        x = self.fc3(x)\n","        return x"],"metadata":{"id":"pw_LDN8v5HTI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code initializes the CNN model, sets cross-entropy as the loss function, and configures SGD with learning rate 0.001 and momentum 0.9 as the optimizer."],"metadata":{"id":"v9CRdLChCQgV"}},{"cell_type":"code","source":["net = NeuralNet()\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optimm.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"dcHO3UE56crU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code trains the network for 8 epochs by looping over training batches, computing loss, backpropagating, updating weights, and printing the average loss per epoch."],"metadata":{"id":"z1mOg5N1AK3c"}},{"cell_type":"code","source":["for epoch in range(8):\n","  print(f'Epoch: {epoch}')\n","\n","  running_loss = 0.0\n","  for i, data in enumerate(train_loader, 0):\n","    inputs, labels = data\n","\n","    optimizer.zero_grad()\n","\n","    outputs = net(inputs)\n","    loss = loss_function(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","\n","  print(f'Loss: {running_loss / len(train_loader):4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAmwi1eM7JCi","executionInfo":{"status":"ok","timestamp":1755268362952,"user_tz":-345,"elapsed":1651965,"user":{"displayName":"Suman Kulung","userId":"01909858237713173636"}},"outputId":"8d65c200-ba4d-4af1-b4bd-d3138a5aaa18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0\n","Loss: 1.671723\n","Epoch: 1\n","Loss: 1.327918\n","Epoch: 2\n","Loss: 1.152655\n","Epoch: 3\n","Loss: 1.026143\n","Epoch: 4\n","Loss: 0.921154\n","Epoch: 5\n","Loss: 0.841139\n","Epoch: 6\n","Loss: 0.778164\n","Epoch: 7\n","Loss: 0.724224\n"]}]},{"cell_type":"code","source":["torch.save(net.state_dict(), 'trained_net.pth')"],"metadata":{"id":"m7d3kTOp9AKj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = NeuralNet()\n","net.load_state_dict(torch.load('trained_net.pth'))"],"metadata":{"id":"JjQWgt9mhOIl","executionInfo":{"status":"ok","timestamp":1755268384381,"user_tz":-345,"elapsed":7,"user":{"displayName":"Suman Kulung","userId":"01909858237713173636"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"005b6462-df6e-4352-da22-9b2ec51997f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["This code evaluates the trained model on the test set by comparing predictions with true labels and computes the overall classification accuracy."],"metadata":{"id":"D4AAwUHeAYhQ"}},{"cell_type":"code","source":["correct = 0\n","total = 0\n","\n","net.eval()\n","\n","with torch.no_grad():\n","  for data in test_loader:\n","    images, labels = data\n","    outputs = net(images)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f'Accuracy: {accuracy}')"],"metadata":{"id":"FSoe2RD5jc_2","executionInfo":{"status":"ok","timestamp":1755268398039,"user_tz":-345,"elapsed":9688,"user":{"displayName":"Suman Kulung","userId":"01909858237713173636"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d745a04-ccf5-4c32-9624-5ead97f15a6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 75.62\n"]}]},{"cell_type":"markdown","source":["This code loads and preprocesses custom images, passes them through the trained model in evaluation mode, and prints the predicted class labels."],"metadata":{"id":"5ggvVLgNAkuE"}},{"cell_type":"code","source":["new_transform = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","\n","def load_image(image_path):\n","    image = Image.open(image_path)\n","    image = new_transform(image)\n","    image = image.unsqueeze(0)  # add batch dimension\n","    return image\n","\n","image_path = ['example1.jpg', 'example2.jpg', 'example3.jpg']\n","images = [load_image(img) for img in image_paths]\n","\n","net.eval()\n","with torch.no_grad():\n","    for image in images:\n","        output = net(image)\n","        _, predicted = torch.max(output.data, 1)\n","        print(f'Prediction: {class_names[predicted.item()]}')"],"metadata":{"id":"p6nZz-b9lTfX","executionInfo":{"status":"ok","timestamp":1755268401344,"user_tz":-345,"elapsed":270,"user":{"displayName":"Suman Kulung","userId":"01909858237713173636"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26370f13-0891-42f5-f2fb-c7e1160cb78a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: plane\n","Prediction: dog\n","Prediction: horse\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZLNNmKxv7uiB"},"execution_count":null,"outputs":[]}]}